{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import join\n",
    "from numpy import asarray\n",
    "from numpy import savez_compressed\n",
    "from keras_preprocessing.image import img_to_array, load_img\n",
    "from tqdm import tqdm\n",
    "from numpy import load\n",
    "from numpy import arange\n",
    "import numpy\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(path, SIZE=(256, 256, 3)):\n",
    "    malware, cl = [], []\n",
    "    for TYPE in tqdm(listdir(path)):\n",
    "        if TYPE == '.DS_Store':\n",
    "            continue\n",
    "        CLASS_PATH = join(path, TYPE)\n",
    "        for IMG in listdir(CLASS_PATH):\n",
    "            if IMG == '.DS_Store':\n",
    "                continue\n",
    "            IMG_PATH = join(CLASS_PATH, IMG)\n",
    "            malware.append(img_to_array(load_img(IMG_PATH, target_size=SIZE)))\n",
    "            cl.append(TYPE)\n",
    "    return [asarray(malware), asarray(cl)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [01:02<00:00,  1.96s/it]\n",
      "100%|██████████| 32/32 [00:24<00:00,  1.33it/s]\n"
     ]
    }
   ],
   "source": [
    "byteplots_train, classes_train = load_images('/Applications/ML projects/Blended Malware/Dataset/train')\n",
    "byteplots_val, classes_val = load_images('/Applications/ML projects/Blended Malware/Dataset/val')\n",
    "\n",
    "train_file = 'train_file.npz'\n",
    "test_file = 'test_file.npz'\n",
    "\n",
    "savez_compressed(train_file, byteplots_train, classes_train)\n",
    "savez_compressed(test_file, byteplots_val, classes_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.losses import SparseCategoricalCrossentropy\n",
    "from keras import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convModel(SIZE=(256, 256, 3)):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=32, kernel_size=(4, 4), strides=(2, 2), padding='same', input_shape=SIZE))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(4, 4), strides=(2, 2), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Conv2D(filters=128, kernel_size=(4, 4), strides=(2, 2), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Conv2D(filters=256, kernel_size=(4, 4), strides=(2, 2), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Conv2D(filters=512, kernel_size=(4, 4), strides=(2, 2), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Conv2D(filters=512, kernel_size=(4, 4), strides=(2, 2), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=8192, activation='relu'))\n",
    "    model.add(Dense(units=2048, activation='relu'))\n",
    "    model.add(Dense(units=31, activation='softmax'))\n",
    "\n",
    "    model.compile(loss=SparseCategoricalCrossentropy(from_logits=True), optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_36 (Conv2D)          (None, 128, 128, 32)      1568      \n",
      "                                                                 \n",
      " leaky_re_lu_36 (LeakyReLU)  (None, 128, 128, 32)      0         \n",
      "                                                                 \n",
      " conv2d_37 (Conv2D)          (None, 64, 64, 64)        32832     \n",
      "                                                                 \n",
      " batch_normalization_30 (Bat  (None, 64, 64, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_37 (LeakyReLU)  (None, 64, 64, 64)        0         \n",
      "                                                                 \n",
      " conv2d_38 (Conv2D)          (None, 32, 32, 128)       131200    \n",
      "                                                                 \n",
      " batch_normalization_31 (Bat  (None, 32, 32, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_38 (LeakyReLU)  (None, 32, 32, 128)       0         \n",
      "                                                                 \n",
      " conv2d_39 (Conv2D)          (None, 16, 16, 256)       524544    \n",
      "                                                                 \n",
      " batch_normalization_32 (Bat  (None, 16, 16, 256)      1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_39 (LeakyReLU)  (None, 16, 16, 256)       0         \n",
      "                                                                 \n",
      " conv2d_40 (Conv2D)          (None, 8, 8, 512)         2097664   \n",
      "                                                                 \n",
      " batch_normalization_33 (Bat  (None, 8, 8, 512)        2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_40 (LeakyReLU)  (None, 8, 8, 512)         0         \n",
      "                                                                 \n",
      " conv2d_41 (Conv2D)          (None, 4, 4, 512)         4194816   \n",
      "                                                                 \n",
      " batch_normalization_34 (Bat  (None, 4, 4, 512)        2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_41 (LeakyReLU)  (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 8192)              0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 8192)              67117056  \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 2048)              16779264  \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 31)                63519     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 90,948,351\n",
      "Trainable params: 90,945,407\n",
      "Non-trainable params: 2,944\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = convModel()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_real_samples(filename):\n",
    "  data = load(filename)\n",
    "  byteplots, classes = data['arr_0'], data['arr_1']\n",
    "  byteplots = byteplots / 255.0\n",
    "  return [byteplots, classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_byteplots, train_classes = load_real_samples('/Applications/ML projects/Blended Malware/Dataset/train_file.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle = arange(train_byteplots.shape[0])\n",
    "numpy.random.shuffle(shuffle)\n",
    "train_byteplots = train_byteplots[shuffle]\n",
    "train_classes = train_classes[shuffle]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "train_classes = le.fit_transform(train_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_byteplots, train_classes, epochs=25, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-03 13:43:24.046363: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_byteplots, test_classes = load_real_samples('/Applications/ML projects/Blended Malware/Dataset/test_file.npz')\n",
    "shuffle = arange(test_byteplots.shape[0])\n",
    "numpy.random.shuffle(shuffle)\n",
    "test_byteplots = test_byteplots[shuffle]\n",
    "test_classes = test_classes[shuffle]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "test_classes = le.fit_transform(test_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 [==============================] - 25s 201ms/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "pred_temp = model2.predict(test_byteplots)\n",
    "pred_classes = []\n",
    "for instance in pred_temp:\n",
    "    pred_classes.append(numpy.argmax(instance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacked Test Accuracy: 0.911\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(test_classes, pred_classes)\n",
    "print('Test Accuracy: %.3f' % accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
